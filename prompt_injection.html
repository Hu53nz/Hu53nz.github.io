<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Prompt Injection Attack - Cybersecurity Handbook</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Prompt Injection Attack</h1>
    </header>

    <nav>
        <a href="index.html">Introduction</a>
        <a href="dos_attack.html">Denial of Service Attack & Solution</a>
        <a href="IPD.html">Insecure Plugin Design & Solution</a>
        <a href="prompt_injection.html">Prompt Injection Attack & Solution</a>
        <a href="xss_attack.html">Insecure Output Handling & Solution</a>
    </nav>

    <div class="container">
        <section id="Prompt Injection">
            <h2>What is a Prompt Injection Attack?</h2>
            <p>A prompt injection attack occurs when attackers manipulate the input prompts of a chatbot to produce unintended outputs, such as leaking sensitive information.</p>
            
            <h3>Examples of Prompt Injection Attacks</h3>
            <ul>
                <li><strong>Manipulation:</strong> Attackers modify prompts to expose sensitive information.</li>
                <li><strong>Overriding Instructions:</strong> Attackers inject commands to bypass system restrictions.</li>
            </ul>
            
            <h3>Solutions to Prevent Prompt Injection Attacks</h3>
            <ul>
                <li><strong>Input Validation:</strong> Ensure prompts are validated before being processed.</li>
                <li><strong>Context Management:</strong> Limit the context that prompts can influence.</li>
            </ul>
            <img src="images/prompt_injection_example.png" alt="Prompt Injection Attack Diagram">
        </section>
    </div>

    <footer>
        <p>&copy; 2024 Cybersecurity Handbook for AI Chatbots. All Rights Reserved.</p>
    </footer>
</body>
</html>

